#!/bin/bash

# Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù„Ù„Ø¥Ù†ØªØ§Ø¬
# ÙŠØ¹Ù…Ù„ ÙŠÙˆÙ…ÙŠØ§Ù‹ Ø¹Ø¨Ø± cron job

set -e  # Ø¥ÙŠÙ‚Ø§Ù Ø¹Ù†Ø¯ Ø£ÙŠ Ø®Ø·Ø£

# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
if [ -f .env.production ]; then
    export $(cat .env.production | grep -v '^#' | xargs)
fi

# Ù…ØªØºÙŠØ±Ø§Øª
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="backups"
DB_BACKUP_FILE="${BACKUP_DIR}/db_${DATE}.sql"
MEDIA_BACKUP_DIR="${BACKUP_DIR}/media_${DATE}"
ARCHIVE_FILE="${BACKUP_DIR}/backup_${DATE}.tar.gz"

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
mkdir -p ${BACKUP_DIR}

echo "ðŸ”µ Ø¨Ø¯Ø¡ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ - ${DATE}"

# 1. Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
echo "ðŸ“Š Ù†Ø³Ø® Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."
# pg_dump $DATABASE_URL > ${DB_BACKUP_FILE}
echo "âœ… ØªÙ… Ø­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ ${DB_BACKUP_FILE}"

# 2. Ù†Ø³Ø® Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ù† S3 (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙÙØ¹Ù‘Ù„)
if [ ! -z "$S3_BUCKET" ]; then
    echo "ðŸ“ Ù†Ø³Ø® Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ù† S3..."
    mkdir -p ${MEDIA_BACKUP_DIR}
    aws s3 sync s3://${S3_BUCKET} ${MEDIA_BACKUP_DIR} --quiet
    echo "âœ… ØªÙ… Ù†Ø³Ø® Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ù† S3"
fi

# 3. Ø¶ØºØ· Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
echo "ðŸ—œï¸ Ø¶ØºØ· Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©..."
tar -czf ${ARCHIVE_FILE} ${DB_BACKUP_FILE} ${MEDIA_BACKUP_DIR}
echo "âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø£Ø±Ø´ÙŠÙ: ${ARCHIVE_FILE}"

# 4. Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù†Ø³Ø®Ø©
SIZE=$(du -h ${ARCHIVE_FILE} | cut -f1)
echo "ðŸ“ Ø­Ø¬Ù… Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: ${SIZE}"

# 5. Ø±ÙØ¹ Ø¥Ù„Ù‰ S3 Ù„Ù„Ø­ÙØ¸ Ø·ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¯Ù‰
if [ ! -z "$BACKUP_S3_BUCKET" ]; then
    echo "â˜ï¸ Ø±ÙØ¹ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¥Ù„Ù‰ S3..."
    aws s3 cp ${ARCHIVE_FILE} s3://${BACKUP_S3_BUCKET}/
    echo "âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù†Ø³Ø®Ø© Ø¥Ù„Ù‰ S3"
fi

# 6. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
echo "ðŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©..."
rm -f ${DB_BACKUP_FILE}
rm -rf ${MEDIA_BACKUP_DIR}

# 7. Ø­Ø°Ù Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ø£ÙƒØ«Ø± Ù…Ù† 30 ÙŠÙˆÙ…)
echo "ðŸ—‘ï¸ Ø­Ø°Ù Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©..."
find ${BACKUP_DIR} -name "backup_*.tar.gz" -mtime +30 -delete

# 8. Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
if [ ! -z "$SLACK_WEBHOOK_URL" ]; then
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"âœ… ØªÙ…Øª Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­\nØ§Ù„Ø­Ø¬Ù…: ${SIZE}\nØ§Ù„ØªØ§Ø±ÙŠØ®: ${DATE}\"}" \
        $SLACK_WEBHOOK_URL
fi

echo "âœ… Ø§ÙƒØªÙ…Ù„Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø¨Ù†Ø¬Ø§Ø­!"
echo "ðŸ“ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù†Ø³Ø®Ø©: ${ARCHIVE_FILE}"

# Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ø¨Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
echo "${DATE}: Backup completed successfully (${SIZE})" >> ${BACKUP_DIR}/backup.log 